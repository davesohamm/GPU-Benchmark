# GPU Compute Benchmark and Visualization Tool for Windows

## ğŸ“‹ Project Overview

This is a professional-grade GPU compute benchmarking application designed to measure and compare performance across multiple GPU compute APIs on Windows systems. The tool provides deep insights into GPU architectural differences, memory behavior, and compute efficiency.

### ğŸ¯ Purpose
- **Learning**: Understand how different GPU APIs work at a low level
- **Comparison**: Fair benchmarking across CUDA, OpenCL, and DirectCompute
- **Analysis**: Visualize performance characteristics and bottlenecks
- **Portfolio**: Demonstrate deep GPU programming knowledge for technical interviews

---

## ğŸ–¥ï¸ Your System Specifications

This project was developed and tested on:
- **CPU**: AMD Ryzen 7 4800H (8 cores, 16 threads)
- **GPU**: NVIDIA RTX 3050 (4GB VRAM, Ampere architecture)
- **RAM**: 16 GB
- **OS**: Windows 11

**What this means for you:**
- âœ… **CUDA**: Fully supported (NVIDIA GPU detected)
- âœ… **OpenCL**: Supported (NVIDIA provides OpenCL drivers)
- âœ… **DirectCompute**: Supported (Windows native API)

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     APPLICATION LAYER                        â”‚
â”‚  (User Interface, Benchmark Controller, Result Logging)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CORE FRAMEWORK                            â”‚
â”‚  (Abstract Interfaces, Timing, Device Discovery)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚               â”‚           â”‚          â”‚
â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CUDA    â”‚  â”‚  OpenCL   â”‚  â”‚DirectCmpâ”‚  â”‚  OpenGL   â”‚
â”‚  Backend  â”‚  â”‚  Backend  â”‚  â”‚ Backend â”‚  â”‚ Renderer  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚               â”‚            â”‚              â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚   GPU HARDWARE   â”‚
     â”‚  (RTX 3050)      â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
GPU-Benchmark/
â”‚
â”œâ”€â”€ README.md                          # This file - main project documentation
â”œâ”€â”€ BUILD_GUIDE.md                     # Detailed build instructions
â”œâ”€â”€ ARCHITECTURE.md                    # Deep dive into system architecture
â”œâ”€â”€ RESULTS_INTERPRETATION.md          # How to understand benchmark results
â”‚
â”œâ”€â”€ src/                               # Source code
â”‚   â”œâ”€â”€ main.cpp                       # Application entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                          # Core framework (API-agnostic)
â”‚   â”‚   â”œâ”€â”€ README.md                  # Core framework documentation
â”‚   â”‚   â”œâ”€â”€ IComputeBackend.h          # Abstract interface for all backends
â”‚   â”‚   â”œâ”€â”€ BenchmarkRunner.h/cpp      # Orchestrates benchmark execution
â”‚   â”‚   â”œâ”€â”€ Timer.h/cpp                # High-resolution timing utilities
â”‚   â”‚   â”œâ”€â”€ DeviceDiscovery.h/cpp      # Runtime GPU/API detection
â”‚   â”‚   â””â”€â”€ Logger.h/cpp               # Logging and result export
â”‚   â”‚
â”‚   â”œâ”€â”€ backends/                      # Compute backend implementations
â”‚   â”‚   â”œâ”€â”€ README.md                  # Backend comparison guide
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ cuda/                      # NVIDIA CUDA backend
â”‚   â”‚   â”‚   â”œâ”€â”€ README.md              # CUDA-specific documentation
â”‚   â”‚   â”‚   â”œâ”€â”€ CUDABackend.h/cpp      # CUDA implementation
â”‚   â”‚   â”‚   â””â”€â”€ kernels/               # CUDA kernel implementations
â”‚   â”‚   â”‚       â”œâ”€â”€ vector_add.cu
â”‚   â”‚   â”‚       â”œâ”€â”€ matrix_mul.cu
â”‚   â”‚   â”‚       â”œâ”€â”€ convolution.cu
â”‚   â”‚   â”‚       â””â”€â”€ reduction.cu
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ opencl/                    # OpenCL backend
â”‚   â”‚   â”‚   â”œâ”€â”€ README.md              # OpenCL-specific documentation
â”‚   â”‚   â”‚   â”œâ”€â”€ OpenCLBackend.h/cpp    # OpenCL implementation
â”‚   â”‚   â”‚   â””â”€â”€ kernels/               # OpenCL kernel source strings
â”‚   â”‚   â”‚       â”œâ”€â”€ vector_add.cl
â”‚   â”‚   â”‚       â”œâ”€â”€ matrix_mul.cl
â”‚   â”‚   â”‚       â”œâ”€â”€ convolution.cl
â”‚   â”‚   â”‚       â””â”€â”€ reduction.cl
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ directcompute/             # DirectCompute backend
â”‚   â”‚       â”œâ”€â”€ README.md              # DirectCompute-specific docs
â”‚   â”‚       â”œâ”€â”€ DirectComputeBackend.h/cpp
â”‚   â”‚       â””â”€â”€ shaders/               # HLSL compute shaders
â”‚   â”‚           â”œâ”€â”€ vector_add.hlsl
â”‚   â”‚           â”œâ”€â”€ matrix_mul.hlsl
â”‚   â”‚           â”œâ”€â”€ convolution.hlsl
â”‚   â”‚           â””â”€â”€ reduction.hlsl
â”‚   â”‚
â”‚   â”œâ”€â”€ benchmarks/                    # Benchmark definitions
â”‚   â”‚   â”œâ”€â”€ README.md                  # What each benchmark measures
â”‚   â”‚   â”œâ”€â”€ VectorAddBenchmark.h/cpp
â”‚   â”‚   â”œâ”€â”€ MatrixMulBenchmark.h/cpp
â”‚   â”‚   â”œâ”€â”€ ConvolutionBenchmark.h/cpp
â”‚   â”‚   â””â”€â”€ ReductionBenchmark.h/cpp
â”‚   â”‚
â”‚   â”œâ”€â”€ visualization/                 # OpenGL rendering and GUI
â”‚   â”‚   â”œâ”€â”€ README.md                  # Visualization architecture
â”‚   â”‚   â”œâ”€â”€ Renderer.h/cpp             # OpenGL renderer
â”‚   â”‚   â”œâ”€â”€ GUI.h/cpp                  # User interface
â”‚   â”‚   â””â”€â”€ shaders/                   # OpenGL shaders for visualization
â”‚   â”‚       â”œâ”€â”€ vertex.glsl
â”‚   â”‚       â””â”€â”€ fragment.glsl
â”‚   â”‚
â”‚   â””â”€â”€ utils/                         # Utility functions
â”‚       â”œâ”€â”€ FileIO.h/cpp               # CSV export, file operations
â”‚       â””â”€â”€ SystemInfo.h/cpp           # Hardware information queries
â”‚
â”œâ”€â”€ include/                           # Third-party headers (GLFW, glad, etc.)
â”œâ”€â”€ lib/                               # Third-party libraries
â”œâ”€â”€ build/                             # Build output (generated)
â””â”€â”€ results/                           # Benchmark results (CSV files)
```

---

## ğŸ”¬ What This Tool Measures

### 1. **Kernel Execution Time**
Pure GPU compute time, excluding all host-side overhead and data transfers.

### 2. **Memory Transfer Time**
- Host â†’ Device (Upload time)
- Device â†’ Host (Download time)

### 3. **Memory Bandwidth**
Effective data throughput in GB/s during transfers and compute operations.

### 4. **Dispatch Latency**
Time overhead to launch a kernel (important for understanding API differences).

### 5. **Scaling Behavior**
How performance changes as problem size increases (weak scaling analysis).

### 6. **Compute Efficiency**
Achieved FLOPS compared to theoretical GPU peak performance.

---

## ğŸ§ª Benchmark Suite

### 1. **Vector Addition** (`C[i] = A[i] + B[i]`)
- **Tests**: Memory bandwidth, kernel launch overhead
- **Use Case**: Stream processing, element-wise operations
- **Memory Pattern**: Perfectly coalesced, streaming access

### 2. **Matrix Multiplication** (`C = A Ã— B`)
- **Tests**: Compute intensity, cache utilization, shared memory
- **Use Case**: Deep learning, scientific computing
- **Memory Pattern**: Complex strided access, cache-dependent

### 3. **2D Convolution** (Image filtering)
- **Tests**: Memory access patterns, texture cache, constant memory
- **Use Case**: Computer vision, image processing
- **Memory Pattern**: Overlapping reads, halo regions

### 4. **Parallel Reduction** (Sum all elements)
- **Tests**: Synchronization, shared memory, warp/wavefront efficiency
- **Use Case**: Aggregations, statistics
- **Memory Pattern**: Tree-based reduction, bank conflicts

---

## ğŸš€ Quick Start

### Prerequisites
1. **Visual Studio 2019 or 2022** with C++ desktop development tools
2. **NVIDIA CUDA Toolkit** (version 11.0 or higher) - [Download here](https://developer.nvidia.com/cuda-downloads)
3. **Windows SDK** (included with Visual Studio)
4. **GPU Drivers** (latest from NVIDIA)

### Building the Project

```powershell
# 1. Clone or extract this project to a local directory
cd y:\GPU-Benchmark

# 2. Open Visual Studio solution
start GPU-Benchmark.sln

# 3. Build the solution (Release mode recommended)
# Press Ctrl+Shift+B or use Build â†’ Build Solution

# 4. Run the executable
.\build\Release\GPU-Benchmark.exe
```

Detailed build instructions are in [`BUILD_GUIDE.md`](BUILD_GUIDE.md).

---

## ğŸ“Š Using the Application

### GUI Mode (Default)
1. Launch `GPU-Benchmark.exe`
2. The application will automatically detect your GPU and supported APIs
3. Select benchmarks from the list
4. Choose which backends to run (CUDA/OpenCL/DirectCompute)
5. Configure problem sizes (Small/Medium/Large)
6. Click "Run Benchmarks"
7. View real-time results in the visualization window
8. Export results to CSV for further analysis

### Command-Line Mode
```powershell
# Run all benchmarks on all available backends
GPU-Benchmark.exe --all

# Run specific benchmark
GPU-Benchmark.exe --benchmark=matrix_mul --backend=cuda

# Specify output file
GPU-Benchmark.exe --all --output=results.csv
```

---

## ğŸ“ˆ Understanding Results

### Sample Output Message
```
=== GPU Compute Benchmark Tool ===
Detected Hardware: NVIDIA GeForce RTX 3050 Laptop GPU
Driver Version: 546.12
CUDA Compute Capability: 8.6

Available Backends:
âœ“ CUDA: Enabled (NVIDIA GPU detected)
âœ“ OpenCL: Enabled (OpenCL 3.0)
âœ“ DirectCompute: Enabled (DirectX 11.0)

Running Vector Addition (1M elements)...
  CUDA:          0.234 ms (execution)  |  1.23 ms (transfer)  |  89.2 GB/s
  OpenCL:        0.289 ms (execution)  |  1.45 ms (transfer)  |  76.4 GB/s
  DirectCompute: 0.312 ms (execution)  |  1.67 ms (transfer)  |  71.8 GB/s
```

### What to Look For
- **CUDA typically fastest**: Direct hardware access on NVIDIA GPUs
- **OpenCL overhead**: Cross-platform abstraction cost
- **DirectCompute integration**: Best Windows API integration
- **Memory transfer bottleneck**: Often dominates small workloads

See [`RESULTS_INTERPRETATION.md`](RESULTS_INTERPRETATION.md) for detailed analysis guidance.

---

## ğŸ“ Learning Outcomes

By studying this project, you'll understand:

1. **GPU Architecture**: How modern GPUs execute parallel workloads
2. **Memory Hierarchies**: Global vs shared vs constant memory trade-offs
3. **API Differences**: Why CUDA, OpenCL, and DirectCompute exist
4. **Performance Analysis**: Identifying bottlenecks (compute vs memory bound)
5. **Low-Level Windows Programming**: DirectX integration, driver interaction
6. **Software Architecture**: Clean separation between backends and visualization
7. **Real-Time Rendering**: OpenGL integration with compute results

---

## ğŸ”§ Customization and Extension

### Adding a New Benchmark
1. Create new class inheriting from `IBenchmark` in `src/benchmarks/`
2. Implement kernels for each backend (CUDA/OpenCL/DirectCompute)
3. Register benchmark in `BenchmarkRunner.cpp`
4. Document expected performance characteristics

### Adding a New Backend (e.g., Vulkan Compute)
1. Create new directory in `src/backends/vulkan/`
2. Implement `IComputeBackend` interface
3. Add detection logic in `DeviceDiscovery.cpp`
4. Implement equivalent kernels for all benchmarks

---

## ğŸ› Troubleshooting

### "CUDA backend failed to initialize"
- **Cause**: CUDA toolkit not installed or NVIDIA driver outdated
- **Solution**: Install CUDA Toolkit and update GPU drivers

### "OpenCL backend unavailable"
- **Cause**: OpenCL ICD loader not found
- **Solution**: Update GPU drivers (vendors include OpenCL support)

### "DirectCompute backend failed"
- **Cause**: DirectX runtime issue
- **Solution**: Update Windows and run Windows Update

### Application crashes on launch
- **Cause**: Missing dependencies
- **Solution**: Install Visual C++ Redistributable 2022

---

## ğŸ“š Additional Documentation

- **[BUILD_GUIDE.md](BUILD_GUIDE.md)**: Step-by-step compilation instructions
- **[ARCHITECTURE.md](ARCHITECTURE.md)**: Deep dive into design decisions
- **[RESULTS_INTERPRETATION.md](RESULTS_INTERPRETATION.md)**: How to analyze results
- **[src/core/README.md](src/core/README.md)**: Core framework documentation
- **[src/backends/README.md](src/backends/README.md)**: Backend comparison guide

---

## ğŸ™ Acknowledgments

This project demonstrates understanding of:
- NVIDIA CUDA programming model
- Khronos OpenCL specification
- Microsoft DirectCompute and HLSL
- OpenGL rendering pipeline
- High-performance C++ development
- Windows driver model interaction

---

## ğŸ“ Interview Talking Points

When discussing this project:

1. **Architecture**: Explain the modular backend design and abstraction layers
2. **Performance**: Discuss memory coalescing, occupancy, and memory bandwidth
3. **Trade-offs**: CUDA performance vs OpenCL portability vs DirectCompute integration
4. **Measurement**: How to accurately time GPU operations without polluting results
5. **Hardware**: How different GPU architectures (NVIDIA, AMD, Intel) behave
6. **Scalability**: How performance changes with problem size

---

## ğŸ“„ License

This project is created for educational and portfolio purposes.

---

**Author**: Soham  
**Hardware**: AMD Ryzen 7 4800H | NVIDIA RTX 3050 | 16GB RAM  
**System**: Windows 11  
**Created**: 2026

---

**Remember**: This tool shows relative performance differences between APIs on YOUR hardware. Results will vary on different systems - that's expected and demonstrates the hardware-dependent nature of GPU computing!
